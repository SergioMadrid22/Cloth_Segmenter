{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "#from datasets import Dataset, DatasetDict, Features, Value, Image\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/media/sergio/6A4A30C94A3093B3/Users/sergi/Desktop/datasets/imaterialist/train.csv\")\n",
    "train_path = '/media/sergio/6A4A30C94A3093B3/Users/sergi/Desktop/datasets/imaterialist/images/train'\n",
    "test_path = '/media/sergio/6A4A30C94A3093B3/Users/sergi/Desktop/datasets/imaterialist/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\sergi\\\\Desktop\\\\datasets\\\\imaterialist\\\\label_descriptions.json', 'r') as f:\n",
    "    label_descriptions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://ccshenyltw.medium.com/run-length-encode-and-decode-a33383142e6b\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated: [start0] [length0] [start1] [length1]... in 1d array\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array according to the shape, 1 - mask, 0 - background\n",
    "    '''\n",
    "    shape = (shape[1], shape[0])\n",
    "    s = mask_rle.split()\n",
    "    # gets starts & lengths 1d arrays\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
    "    starts -= 1\n",
    "    # gets ends 1d array\n",
    "    ends = starts + lengths\n",
    "    # creates blank mask image 1d array\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    # sets mark pixels\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    # reshape as a 2d mask image\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a multi-class segmentation mask\n",
    "def create_multiclass_mask(image_id, df):\n",
    "    \"\"\"\n",
    "    Create a multi-class segmentation mask for an image\n",
    "    \n",
    "    Args:\n",
    "        image_id (str): Image ID\n",
    "        df (pd.DataFrame): DataFrame containing RLE encoded masks\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Multi-class segmentation mask\n",
    "    \"\"\"\n",
    "    # Get all rows for this image\n",
    "    image_df = df[df['ImageId'] == image_id]\n",
    "    \n",
    "    # Get height and width\n",
    "    height = image_df['Height'].iloc[0]\n",
    "    width = image_df['Width'].iloc[0]\n",
    "    \n",
    "    # Create empty mask\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Fill mask with class IDs\n",
    "    for _, row in image_df.iterrows():\n",
    "        class_id = row['ClassId']\n",
    "        encoded_pixels = row['EncodedPixels']\n",
    "        \n",
    "        # Decode RLE\n",
    "        class_mask = rle_decode(encoded_pixels, (height, width))\n",
    "        \n",
    "        # Add class to the mask (only where class_mask is 1)\n",
    "        mask = np.where(class_mask == 1, class_id, mask)\n",
    "        \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_image_ids = train_df['ImageId'].unique()\n",
    "# Create a directory to save the masks\n",
    "os.makedirs('segformer_data/masks', exist_ok=True)\n",
    "os.makedirs('segformer_data/images', exist_ok=True)\n",
    "# Process a sample of images (adjust the range as needed)\n",
    "sample_size = min(5, len(unique_image_ids))  # Start with a small sample for testing\n",
    "for image_id in tqdm(unique_image_ids[:sample_size], desc=\"Processing images\"):\n",
    "    # Create multi-class mask\n",
    "    mask = create_multiclass_mask(image_id, train_df)\n",
    "    \n",
    "    # Save the mask\n",
    "    cv2.imwrite(f'segformer_data/masks/{image_id}.png', mask)\n",
    "    \n",
    "    # Copy the original image (assuming images are in a directory named 'train_images')\n",
    "    # Adjust the path as needed\n",
    "    os.system(f'copy {train_path}\\\\{image_id}.jpg segformer_data\\\\images\\\\')\n",
    "\n",
    "# Visualize all masks in the masks folder\n",
    "mask_files = os.listdir('segformer_data/masks')\n",
    "num_masks = len(mask_files)\n",
    "rows = (num_masks + 2) // 3  # Calculate number of rows needed (3 images per row)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * rows))\n",
    "for idx, mask_file in enumerate(mask_files):\n",
    "    mask = cv2.imread(f'segformer_data/masks/{mask_file}', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    plt.subplot(rows, 3, idx + 1)\n",
    "    plt.imshow(mask, cmap='tab20')\n",
    "    plt.title(f'Mask: {mask_file}')\n",
    "    plt.colorbar(label='Class ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ---------------------------\n",
    "# Mask Creation Function (per image group)\n",
    "# ---------------------------\n",
    "def create_multiclass_mask_from_group(group, target_size=(512, 512)):\n",
    "    height, width = target_size\n",
    "    mask = np.full((height, width), 255, dtype=np.uint8)\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        class_id = int(row.ClassId)\n",
    "        decoded_mask = rle_decode(row.EncodedPixels, (row.Height, row.Width))\n",
    "        resized_mask = cv2.resize(decoded_mask, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "        mask[resized_mask == 1] = class_id\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# ---------------------------\n",
    "# Image Processing Function (parallel unit)\n",
    "# ---------------------------\n",
    "def process_single_image(image_id, group, image_dir, output_dir, target_size=(512, 512)):\n",
    "    try:\n",
    "        # Create and save multiclass mask\n",
    "        mask = create_multiclass_mask_from_group(group, target_size)\n",
    "        mask_path = os.path.join(output_dir, \"masks\", f\"{image_id}.png\")\n",
    "        cv2.imwrite(mask_path, mask)\n",
    "\n",
    "        # Copy original image\n",
    "        src_path = os.path.join(image_dir, f\"{image_id}.jpg\")\n",
    "        dst_path = os.path.join(output_dir, \"images\", f\"{image_id}.jpg\")\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            img = Image.open(src_path)\n",
    "            img = img.resize(target_size, Image.BILINEAR)  # Resize to match mask\n",
    "            img.save(dst_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_id}: {e}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Main Dataset Processor\n",
    "# ---------------------------\n",
    "def process_full_dataset_parallel(df, image_dir, output_dir, target_size=(512, 512), num_workers=8):\n",
    "    os.makedirs(os.path.join(output_dir, \"masks\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
    "\n",
    "    grouped = df.groupby(\"ImageId\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_single_image, image_id, group, image_dir, output_dir, target_size)\n",
    "            for image_id, group in grouped\n",
    "        ]\n",
    "\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures), desc=\"Processing full dataset\"):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing full dataset: 100%|██████████| 45623/45623 [22:20<00:00, 34.03it/s]\n"
     ]
    }
   ],
   "source": [
    "process_full_dataset_parallel(\n",
    "    train_df,\n",
    "    image_dir=train_path,\n",
    "    output_dir=\"/home/sergio/datasets/imaterialist_processed\",\n",
    "    target_size=(512, 512),\n",
    "    num_workers=14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
